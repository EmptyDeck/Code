{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO CAR\n",
    "2023 08 16  \n",
    "1540i  \n",
    "let get init  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vid_4_18340.jpg',\n",
       " 'vid_4_2460.jpg',\n",
       " 'vid_4_10720.jpg',\n",
       " 'vid_4_14220.jpg',\n",
       " 'vid_4_6160.jpg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()  #Here\n",
    "# List the contents of the \"data\" directory\n",
    "train_path = os.path.join(current_dir, \"training_images\")\n",
    "data_directory_contents = os.listdir(train_path)\n",
    "data_directory_contents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vid_5_30040.jpg',\n",
       " 'vid_5_27500.jpg',\n",
       " 'vid_5_28380.jpg',\n",
       " 'vid_5_26420.jpg',\n",
       " 'vid_5_31160.jpg']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()  #Here\n",
    "# List the contents of the \"data\" directory\n",
    "test_path = os.path.join(current_dir, \"testing_images\")\n",
    "data_directory_contents = os.listdir(test_path)\n",
    "data_directory_contents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vid_4_1000.jpg</td>\n",
       "      <td>281.259045</td>\n",
       "      <td>187.035071</td>\n",
       "      <td>327.727931</td>\n",
       "      <td>223.225547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vid_4_10000.jpg</td>\n",
       "      <td>15.163531</td>\n",
       "      <td>187.035071</td>\n",
       "      <td>120.329957</td>\n",
       "      <td>236.430180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vid_4_10040.jpg</td>\n",
       "      <td>239.192475</td>\n",
       "      <td>176.764801</td>\n",
       "      <td>361.968162</td>\n",
       "      <td>236.430180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vid_4_10020.jpg</td>\n",
       "      <td>496.483358</td>\n",
       "      <td>172.363256</td>\n",
       "      <td>630.020260</td>\n",
       "      <td>231.539575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vid_4_10060.jpg</td>\n",
       "      <td>16.630970</td>\n",
       "      <td>186.546010</td>\n",
       "      <td>132.558611</td>\n",
       "      <td>238.386422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image        xmin        ymin        xmax        ymax\n",
       "0   vid_4_1000.jpg  281.259045  187.035071  327.727931  223.225547\n",
       "1  vid_4_10000.jpg   15.163531  187.035071  120.329957  236.430180\n",
       "2  vid_4_10040.jpg  239.192475  176.764801  361.968162  236.430180\n",
       "3  vid_4_10020.jpg  496.483358  172.363256  630.020260  231.539575\n",
       "4  vid_4_10060.jpg   16.630970  186.546010  132.558611  238.386422"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the bounding boxes CSV file\n",
    "bounding_boxes_csv_path = os.path.join(current_dir, \"train_solution_bounding_boxes.csv\")\n",
    "bounding_boxes_df = pd.read_csv(bounding_boxes_csv_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "bounding_boxes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>yolo_format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vid_4_1000.jpg</td>\n",
       "      <td>281.259045</td>\n",
       "      <td>187.035071</td>\n",
       "      <td>327.727931</td>\n",
       "      <td>223.225547</td>\n",
       "      <td>0 0.45043415340236687 0.539816602368421 0.0687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vid_4_10000.jpg</td>\n",
       "      <td>15.163531</td>\n",
       "      <td>187.035071</td>\n",
       "      <td>120.329957</td>\n",
       "      <td>236.430180</td>\n",
       "      <td>0 0.10021707670857989 0.5571911197368421 0.155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vid_4_10040.jpg</td>\n",
       "      <td>239.192475</td>\n",
       "      <td>176.764801</td>\n",
       "      <td>361.968162</td>\n",
       "      <td>236.430180</td>\n",
       "      <td>0 0.44464544142011836 0.5436776061842105 0.181...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vid_4_10020.jpg</td>\n",
       "      <td>496.483358</td>\n",
       "      <td>172.363256</td>\n",
       "      <td>630.020260</td>\n",
       "      <td>231.539575</td>\n",
       "      <td>0 0.8332127352071006 0.5314510939473683 0.1975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vid_4_10060.jpg</td>\n",
       "      <td>16.630970</td>\n",
       "      <td>186.546010</td>\n",
       "      <td>132.558611</td>\n",
       "      <td>238.386422</td>\n",
       "      <td>0 0.11034732271449704 0.5591216215789474 0.171...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image        xmin        ymin        xmax        ymax  \\\n",
       "0   vid_4_1000.jpg  281.259045  187.035071  327.727931  223.225547   \n",
       "1  vid_4_10000.jpg   15.163531  187.035071  120.329957  236.430180   \n",
       "2  vid_4_10040.jpg  239.192475  176.764801  361.968162  236.430180   \n",
       "3  vid_4_10020.jpg  496.483358  172.363256  630.020260  231.539575   \n",
       "4  vid_4_10060.jpg   16.630970  186.546010  132.558611  238.386422   \n",
       "\n",
       "                                         yolo_format  \n",
       "0  0 0.45043415340236687 0.539816602368421 0.0687...  \n",
       "1  0 0.10021707670857989 0.5571911197368421 0.155...  \n",
       "2  0 0.44464544142011836 0.5436776061842105 0.181...  \n",
       "3  0 0.8332127352071006 0.5314510939473683 0.1975...  \n",
       "4  0 0.11034732271449704 0.5591216215789474 0.171...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def convert_to_yolo_format(row, img_path):\n",
    "    # Open the image to get its width and height\n",
    "    with Image.open(img_path) as img:\n",
    "        img_width, img_height = img.size\n",
    "    \n",
    "    # Calculate center, width and height of the bounding box\n",
    "    center_x = (row['xmin'] + row['xmax']) / 2.0\n",
    "    center_y = (row['ymin'] + row['ymax']) / 2.0\n",
    "    width = row['xmax'] - row['xmin']\n",
    "    height = row['ymax'] - row['ymin']\n",
    "    \n",
    "    # Normalize the values\n",
    "    center_x /= img_width\n",
    "    center_y /= img_height\n",
    "    width /= img_width\n",
    "    height /= img_height\n",
    "    \n",
    "    return f\"0 {center_x} {center_y} {width} {height}\"\n",
    "\n",
    "# Apply the conversion to each row in the dataframe\n",
    "training_images_path = os.path.join(current_dir, \"training_images\")\n",
    "bounding_boxes_df['yolo_format'] = bounding_boxes_df.apply(lambda row: convert_to_yolo_format(row, os.path.join(training_images_path, row['image'])), axis=1)\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "bounding_boxes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vid_4_740.txt',\n",
       " 'vid_4_6260.txt',\n",
       " 'vid_4_13840.txt',\n",
       " 'vid_4_15000.txt',\n",
       " 'vid_4_21400.txt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory to save YOLO formatted labels\n",
    "labels_directory = os.path.join(current_dir, \"yolo_labels\")\n",
    "os.makedirs(labels_directory, exist_ok=True)\n",
    "\n",
    "for _, row in bounding_boxes_df.iterrows():\n",
    "    # Create a text file for each image with the corresponding YOLO format data\n",
    "    txt_filename = os.path.splitext(row['image'])[0] + '.txt'\n",
    "    txt_path = os.path.join(labels_directory, txt_filename)\n",
    "    with open(txt_path, 'w') as f:\n",
    "        f.write(row['yolo_format'] + \"\\n\")\n",
    "\n",
    "# Check the first few created files\n",
    "created_files = os.listdir(labels_directory)[:5]\n",
    "created_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/owo/HOUSE/@Code/@Project/ID_CarObjectDetection/dataset.data'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a names file for class names\n",
    "classes_names_path = os.path.join(current_dir, \"classes.names\")\n",
    "with open(classes_names_path, 'w') as f:\n",
    "    f.write(\"object\\n\")  # Only one class named \"object\"\n",
    "\n",
    "# Create a data file with paths to datasets and class names\n",
    "data_file_content = f\"\"\"\n",
    "classes = 1\n",
    "train = {os.path.join(current_dir, \"train.txt\")}\n",
    "valid = {os.path.join(current_dir, \"valid.txt\")}\n",
    "names = {classes_names_path}\n",
    "backup = backup/\n",
    "\"\"\"\n",
    "\n",
    "data_file_path = os.path.join(current_dir, \"dataset.data\")\n",
    "with open(data_file_path, 'w') as f:\n",
    "    f.write(data_file_content)\n",
    "\n",
    "data_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/owo/HOUSE/@Code/@Project/ID_CarObjectDetection/train.txt',\n",
       " '/Users/owo/HOUSE/@Code/@Project/ID_CarObjectDetection/valid.txt')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Get all training image paths\n",
    "all_image_paths = [os.path.join(training_images_path, img_name) for img_name in bounding_boxes_df['image'].tolist()]\n",
    "\n",
    "# Shuffle and split the dataset into training and validation sets\n",
    "random.shuffle(all_image_paths)\n",
    "split_point = int(0.9 * len(all_image_paths))\n",
    "train_images = all_image_paths[:split_point]\n",
    "valid_images = all_image_paths[split_point:]\n",
    "\n",
    "# Save the paths to train.txt and valid.txt files\n",
    "train_txt_path = os.path.join(current_dir, \"train.txt\")\n",
    "valid_txt_path = os.path.join(current_dir, \"valid.txt\")\n",
    "\n",
    "with open(train_txt_path, 'w') as f:\n",
    "    f.write(\"\\n\".join(train_images))\n",
    "\n",
    "with open(valid_txt_path, 'w') as f:\n",
    "    f.write(\"\\n\".join(valid_images))\n",
    "\n",
    "train_txt_path, valid_txt_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image size fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676, 380)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the first image to get its dimensions\n",
    "with Image.open(all_image_paths[0]) as img:\n",
    "    img_width, img_height = img.size\n",
    "\n",
    "img_width, img_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704, 384)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the network width and height as multiples of 32\n",
    "network_width = (img_width + 31) // 32 * 32\n",
    "network_height = (img_height + 31) // 32 * 32\n",
    "\n",
    "network_width, network_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/owo/HOUSE/@Code/@Project/ID_CarObjectDetection/yolov3_custom.cfg'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOLOv3 configuration for training\n",
    "yolov3_config = f\"\"\"\n",
    "[net]\n",
    "# Testing\n",
    "batch=4\n",
    "subdivisions=2\n",
    "# Training\n",
    "# batch=64\n",
    "# subdivisions=16\n",
    "width={network_width}\n",
    "height={network_height}\n",
    "channels=3\n",
    "momentum=0.9\n",
    "decay=0.0005\n",
    "angle=0\n",
    "saturation = 1.5\n",
    "exposure = 1.5\n",
    "hue=.1\n",
    "\n",
    "learning_rate=0.001\n",
    "burn_in=1000\n",
    "max_batches = 500200\n",
    "policy=steps\n",
    "steps=400000,450000\n",
    "scales=.1,.1\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=32\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "# ... (Many more layers)\n",
    "\n",
    "[region]\n",
    "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
    "bias_match=1\n",
    "classes=1\n",
    "coords=4\n",
    "num=9\n",
    "jitter=.3\n",
    "ignore_thresh = .7\n",
    "truth_thresh = 1\n",
    "random=1\n",
    "\"\"\"\n",
    "\n",
    "# Save the configuration to a file\n",
    "cfg_path = os.path.join(current_dir, \"yolov3_custom.cfg\")\n",
    "with open(cfg_path, 'w') as f:\n",
    "    f.write(yolov3_config)\n",
    "\n",
    "cfg_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "class YOLODataset(Dataset):\n",
    "    def __init__(self, list_path, img_size=416):\n",
    "        with open(list_path, 'r') as file:\n",
    "            self.img_files = file.readlines()\n",
    "        \n",
    "        self.label_files = [path.replace('images', 'labels').replace('.png', '.txt').replace('.jpg', '.txt') for path in self.img_files]\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_files[index % len(self.img_files)].rstrip()\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = img.resize((self.img_size, self.img_size))\n",
    "        img = np.array(img, dtype=np.float32) / 255.0  # Normalize to [0, 1]\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1)  # Convert to (C, H, W) format\n",
    "\n",
    "        label_path = self.label_files[index % len(self.img_files)].rstrip()\n",
    "        labels = torch.zeros((0, 5), dtype=torch.float32)  # Default empty label\n",
    "        if os.path.exists(label_path):\n",
    "            labels_data = [list(map(float, line.split())) for line in open(label_path)]\n",
    "            if labels_data:\n",
    "                labels = torch.tensor(labels_data, dtype=torch.float32)\n",
    "\n",
    "        return img, labels\n",
    "\n",
    "# Example usage\n",
    "dataset = YOLODataset(train_txt_path, img_size=704)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "next(iter(dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from models import Darknet\n",
    "from utils.datasets import ListDataset\n",
    "from utils.utils import compute_loss\n",
    "\n",
    "# Configuration\n",
    "cfg = '/path/to/yolov3_custom.cfg'\n",
    "data_config = '/path/to/dataset.data'\n",
    "img_size = 704\n",
    "epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = Darknet(cfg, img_size=img_size).to(device)\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Get dataloader\n",
    "train_path = '/path/to/train.txt'\n",
    "dataset = ListDataset(train_path, img_size=img_size)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=dataset.collate_fn)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for batch_i, (imgs, targets) in enumerate(dataloader):\n",
    "        # Send to GPU\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(imgs)\n",
    "        loss, loss_components = compute_loss(outputs, targets, model)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Print log\n",
    "        print(f\"Epoch {epoch}/{epochs}, Batch {batch_i}/{len(dataloader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    # Save model weights periodically\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), f\"weights_epoch_{epoch}.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
